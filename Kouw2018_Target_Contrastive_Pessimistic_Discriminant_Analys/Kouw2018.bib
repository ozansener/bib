@article { Kouw2018,
	abstract = {Domain-adaptive classifiers learn from a source domain and aim to generalize
to a target domain. If the classifier's assumptions on the relationship between
domains (e.g. covariate shift) are valid, then it will usually outperform a
non-adaptive source classifier. Unfortunately, it can perform substantially
worse when its assumptions are invalid. Validating these assumptions requires
labeled target samples, which are usually not available. We argue that, in
order to make domain-adaptive classifiers more practical, it is necessary to
focus on robust methods; robust in the sense that the model still achieves a
particular level of performance without making strong assumptions on the
relationship between domains. With this objective in mind, we formulate a
conservative parameter estimator that only deviates from the source classifier
when a lower or equal risk is guaranteed for all possible labellings of the
given target samples. We derive the corresponding estimator for a discriminant
analysis model, and show that its risk is actually strictly smaller than that
of the source classifier. Experiments indicate that our classifier outperforms
state-of-the-art classifiers for geographically biased samples.},
	url = {http://arxiv.org/pdf/1806.09463v1},
	eprint = {1806.09463},
	arxivid = {1806.09463},
	archiveprefix = {arXiv},
	month = {Jun},
	year = {2018},
	booktitle = {arXiv},
	title = {{Target Contrastive Pessimistic Discriminant Analysis}},
	author = {Wouter M. Kouw and Marco Loog}
}

