@inproceedings { Sun2019,
	abstract = {In machine learning, models that generalize better often generate outputs that lie on a low-dimensional manifold. Recently, several works have separately shown finite-time manifold identification by some proximal methods.  In this work we provide a unified view by giving a simple condition under which any proximal method using a constant step size can achieve finite-iteration manifold detection. For several key methods (FISTA, DRS, ADMM, SVRG, SAGA, and RDA) we give an  iteration bound, characterized in terms of their variable convergence rate and a problem-dependent constant that indicates problem degeneracy.  For popular models, this constant is related to certain data assumptions, which gives intuition as to when lower active set complexity may be expected in practice.},
	url = {http://proceedings.mlr.press/v89/sun19a.html},
	pdf = {http://proceedings.mlr.press/v89/sun19a/sun19a.pdf},
	publisher = {PMLR},
	month = {16--18 Apr},
	address = {},
	series = {Proceedings of Machine Learning Research},
	volume = {89},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	year = {2019},
	pages = {1110--1119},
	booktitle = {Proceedings of Machine Learning Research},
	title = {{Are we there yet? Manifold identification of gradient-related proximal methods}},
	author = {Sun, Yifan and Jeong, Halyun and Nutini, Julie and Schmidt, Mark}
}

