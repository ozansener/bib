@article { Nguyen2020,
	abstract = {Interpreting the behaviors of Deep Neural Networks (usually considered as a
black box) is critical especially when they are now being widely adopted over
diverse aspects of human life. Taking the advancements from Explainable
Artificial Intelligent, this paper proposes a novel technique called Auto
DeepVis to dissect catastrophic forgetting in continual learning. A new method
to deal with catastrophic forgetting named critical freezing is also introduced
upon investigating the dilemma by Auto DeepVis. Experiments on a captioning
model meticulously present how catastrophic forgetting happens, particularly
showing which components are forgetting or changing. The effectiveness of our
technique is then assessed; and more precisely, critical freezing claims the
best performance on both previous and coming tasks over baselines, proving the
capability of the investigation. Our techniques could not only be supplementary
to existing solutions for completely eradicating catastrophic forgetting for
life-long learning but also explainable.},
	url = {http://arxiv.org/pdf/2001.01578v1},
	eprint = {2001.01578},
	arxivid = {2001.01578},
	archiveprefix = {arXiv},
	month = {Jan},
	year = {2020},
	booktitle = {arXiv},
	title = {{Dissecting Catastrophic Forgetting in Continual Learning by Deep
  Visualization}},
	author = {Giang Nguyen and Shuan Chen and Thao Do and Tae Joon Jun and Ho-Jin Choi and Daeyoung Kim}
}

