@article { Kunstner2019,
	abstract = {Natural gradient descent, which preconditions a gradient descent update with
the Fisher information matrix of the underlying statistical model, is a way to
capture partial second-order information. Several highly visible works have
advocated an approximation known as the empirical Fisher, drawing connections
between approximate second-order methods and heuristics like Adam. We dispute
this argument by showing that the empirical Fisher---unlike the Fisher---does
not generally capture second-order information. We further argue that the
conditions under which the empirical Fisher approaches the Fisher (and the
Hessian) are unlikely to be met in practice, and that, even on simple
optimization problems, the pathologies of the empirical Fisher can have
undesirable effects.},
	url = {http://arxiv.org/pdf/1905.12558v1},
	eprint = {1905.12558},
	arxivid = {1905.12558},
	archiveprefix = {arXiv},
	month = {May},
	year = {2019},
	booktitle = {arXiv},
	title = {{Limitations of the Empirical Fisher Approximation}},
	author = {Frederik Kunstner and Lukas Balles and Philipp Hennig}
}

