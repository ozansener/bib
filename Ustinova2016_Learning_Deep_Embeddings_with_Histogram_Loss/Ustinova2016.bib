@article { Ustinova2016,
	abstract = {We suggest a loss for learning deep embeddings. The new loss does not
introduce parameters that need to be tuned and results in very good embeddings
across a range of datasets and problems. The loss is computed by estimating two
distribution of similarities for positive (matching) and negative
(non-matching) sample pairs, and then computing the probability of a positive
pair to have a lower similarity score than a negative pair based on the
estimated similarity distributions. We show that such operations can be
performed in a simple and piecewise-differentiable manner using 1D histograms
with soft assignment operations. This makes the proposed loss suitable for
learning deep embeddings using stochastic optimization. In the experiments, the
new loss performs favourably compared to recently proposed alternatives.},
	url = {http://arxiv.org/pdf/1611.00822v1},
	eprint = {1611.00822},
	arxivid = {1611.00822},
	archiveprefix = {arXiv},
	month = {Nov},
	year = {2016},
	booktitle = {arXiv},
	title = {{Learning Deep Embeddings with Histogram Loss}},
	author = {Evgeniya Ustinova and Victor Lempitsky}
}

