@article { Ma2018a,
	abstract = {Optimization algorithms and Monte Carlo sampling algorithms have provided the
computational foundations for the rapid growth in applications of statistical
machine learning in recent years. There is, however, limited theoretical
understanding of the relationships between these two kinds of methodology, and
limited understanding of relative strengths and weaknesses. Moreover, existing
results have been obtained primarily in the setting of convex functions (for
optimization) and log-concave functions (for sampling). In this setting, where
local properties determine global properties, optimization algorithms are
unsurprisingly more efficient computationally than sampling algorithms. We
instead examine a class of nonconvex objective functions that arise in mixture
modeling and multi-stable systems. In this nonconvex setting, we find that the
computational complexity of sampling algorithms scales linearly with the model
dimension while that of optimization algorithms scales exponentially.},
	url = {http://arxiv.org/pdf/1811.08413v1},
	eprint = {1811.08413v1},
	arxivid = {1811.08413v1},
	archiveprefix = {arXiv},
	month = {Nov},
	year = {2018},
	booktitle = {arXiv},
	title = {{Sampling Can Be Faster Than Optimization}},
	author = {Yi-An Ma and Yuansi Chen and Chi Jin and Nicolas Flammarion and Michael I. Jordan}
}

