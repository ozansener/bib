@article { Duan2016,
	abstract = {Recently, researchers have made significant progress combining the advances
in deep learning for learning feature representations with reinforcement
learning. Some notable examples include training agents to play Atari games
based on raw pixel data and to acquire advanced manipulation skills using raw
sensory inputs. However, it has been difficult to quantify progress in the
domain of continuous control due to the lack of a commonly adopted benchmark.
In this work, we present a benchmark suite of continuous control tasks,
including classic tasks like cart-pole swing-up, tasks with very high state and
action dimensionality such as 3D humanoid locomotion, tasks with partial
observations, and tasks with hierarchical structure. We report novel findings
based on the systematic evaluation of a range of implemented reinforcement
learning algorithms. Both the benchmark and reference implementations are
released at https://github.com/rllab/rllab in order to facilitate experimental
reproducibility and to encourage adoption by other researchers.},
	url = {http://arxiv.org/pdf/1604.06778v3},
	eprint = {1604.06778},
	arxivid = {1604.06778},
	archiveprefix = {arXiv},
	month = {Apr},
	year = {2016},
	booktitle = {arXiv},
	title = {{Benchmarking Deep Reinforcement Learning for Continuous Control}},
	author = {Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel}
}

