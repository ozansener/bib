@article { Nalisnick2019,
	abstract = {Recent work has shown that deep generative models can assign higher
likelihood to out-of-distribution data sets than to their training data. We
posit that this phenomenon is caused by a mismatch between the model's typical
set and its areas of high probability density. In-distribution inputs should
reside in the former but not necessarily in the latter, as previous work has
presumed. To determine whether or not inputs reside in the typical set, we
propose a statistically principled, easy-to-implement test using the empirical
distribution of model likelihoods. The test is model agnostic and widely
applicable, only requiring that the likelihood can be computed or closely
approximated. We report experiments showing that our procedure can successfully
detect the out-of-distribution sets in several of the challenging cases
reported by Nalisnick et al. (2019).},
	url = {http://arxiv.org/pdf/1906.02994v1},
	eprint = {1906.02994},
	arxivid = {1906.02994},
	archiveprefix = {arXiv},
	month = {Jun},
	year = {2019},
	booktitle = {arXiv},
	title = {{Detecting Out-of-Distribution Inputs to Deep Generative Models Using a
  Test for Typicality}},
	author = {Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan}
}

