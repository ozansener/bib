@article { Qian2018,
	abstract = {Recently, machine learning becomes important for the cloud computing service.
Users of cloud computing can benefit from the sophisticated machine learning
models provided by the service. Considering that users can come from different
domains with the same problem, an ideal model has to be applicable over
multiple domains. In this work, we propose to address this challenge by
developing a framework of robust optimization. In lieu of minimizing the
empirical risk, we aim to learn a model optimized with an adversarial
distribution over multiple domains. Besides the convex model, we analyze the
convergence rate of learning a robust non-convex model due to its dominating
performance on many real-word applications. Furthermore, we demonstrate that
both the robustness of the framework and the convergence rate can be enhanced
by introducing appropriate regularizers for the adversarial distribution. The
empirical study on real-world fine-grained visual categorization and digits
recognition tasks verifies the effectiveness and efficiency of the proposed
framework.},
	url = {http://arxiv.org/pdf/1805.07588v1},
	eprint = {1805.07588},
	arxivid = {1805.07588},
	archiveprefix = {arXiv},
	month = {May},
	year = {2018},
	booktitle = {arXiv},
	title = {{Robust Optimization over Multiple Domains}},
	author = {Qi Qian and Shenghuo Zhu and Jiasheng Tang and Rong Jin and Baigui Sun and Hao Li}
}

