@article { Marcus2018,
	abstract = {The concept of innateness is rarely discussed in the context of artificial
intelligence. When it is discussed, or hinted at, it is often the context of
trying to reduce the amount of innate machinery in a given system. In this
paper, I consider as a test case a recent series of papers by Silver et al
(Silver et al., 2017a) on AlphaGo and its successors that have been presented
as an argument that a "even in the most challenging of domains: it is possible
to train to superhuman level, without human examples or guidance", "starting
tabula rasa."
  I argue that these claims are overstated, for multiple reasons. I close by
arguing that artificial intelligence needs greater attention to innateness, and
I point to some proposals about what that innateness might look like.},
	url = {http://arxiv.org/pdf/1801.05667v1},
	eprint = {1801.05667},
	arxivid = {1801.05667},
	archiveprefix = {arXiv},
	month = {Jan},
	year = {2018},
	booktitle = {arXiv},
	title = {{Innateness, AlphaZero, and Artificial Intelligence}},
	author = {Gary Marcus}
}

