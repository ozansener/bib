@article { Ho2019,
	abstract = {A key challenge in leveraging data augmentation for neural network training
is choosing an effective augmentation policy from a large search space of
candidate operations. Properly chosen augmentation policies can lead to
significant generalization improvements; however, state-of-the-art approaches
such as AutoAugment are computationally infeasible to run for the ordinary
user. In this paper, we introduce a new data augmentation algorithm, Population
Based Augmentation (PBA), which generates nonstationary augmentation policy
schedules instead of a fixed augmentation policy. We show that PBA can match
the performance of AutoAugment on CIFAR-10, CIFAR-100, and SVHN, with three
orders of magnitude less overall compute. On CIFAR-10 we achieve a mean test
error of 1.46%, which is a slight improvement upon the current
state-of-the-art. The code for PBA is open source and is available at
https://github.com/arcelien/pba.},
	url = {http://arxiv.org/pdf/1905.05393v1},
	eprint = {1905.05393},
	arxivid = {1905.05393},
	archiveprefix = {arXiv},
	month = {May},
	year = {2019},
	booktitle = {arXiv},
	title = {{Population Based Augmentation: Efficient Learning of Augmentation Policy
  Schedules}},
	author = {Daniel Ho and Eric Liang and Ion Stoica and Pieter Abbeel and Xi Chen}
}

