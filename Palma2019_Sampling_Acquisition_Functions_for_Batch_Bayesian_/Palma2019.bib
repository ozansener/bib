@article { Palma2019,
	abstract = {This paper presents Acquisition Thompson Sampling (ATS), a novel algorithm
for batch Bayesian Optimization (BO) based on the idea of sampling multiple
acquisition functions from a stochastic process. We define this process through
the dependency of the acquisition functions on a set of model parameters. ATS
is conceptually simple, straightforward to implement and, unlike other batch BO
methods, it can be employed to parallelize any sequential acquisition function.
In order to improve performance for multi-modal tasks, we show that ATS can be
combined with existing techniques in order to realize different explore-exploit
trade-offs and take into account pending function evaluations. We present
experiments on a variety of benchmark functions and on the hyper-parameter
optimization of a popular gradient boosting tree algorithm. These demonstrate
the competitiveness of our algorithm with two state-of-the-art batch BO
methods, and its advantages to classical parallel Thompson Sampling for BO.},
	url = {http://arxiv.org/pdf/1903.09434v1},
	eprint = {1903.09434},
	arxivid = {1903.09434},
	archiveprefix = {arXiv},
	month = {Mar},
	year = {2019},
	booktitle = {arXiv},
	title = {{Sampling Acquisition Functions for Batch Bayesian Optimization}},
	author = {Alessandro De Palma and Celestine Mendler-DÃ¼nner and Thomas Parnell and Andreea Anghel and Haralampos Pozidis}
}

