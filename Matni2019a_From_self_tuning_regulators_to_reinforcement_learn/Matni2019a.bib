@article { Matni2019a,
	abstract = {Machine and reinforcement learning (RL) are being applied to plan and control
the behavior of autonomous systems interacting with the physical world --
examples include self-driving vehicles, distributed sensor networks, and agile
robots. However, if machine learning is to be applied in these new settings,
the resulting algorithms must come with the reliability, robustness, and safety
guarantees that are hallmarks of the control theory literature, as failures
could be catastrophic. Thus, as RL algorithms are increasingly and more
aggressively deployed in safety critical settings, it is imperative that
control theorists be part of the conversation. The goal of this tutorial paper
is to provide a jumping off point for control theorists wishing to work on RL
related problems by covering recent advances in bridging learning and control
theory, and by placing these results within the appropriate historical context
of the system identification and adaptive control literatures.},
	url = {http://arxiv.org/pdf/1906.11392v1},
	eprint = {1906.11392},
	arxivid = {1906.11392},
	archiveprefix = {arXiv},
	month = {Jun},
	year = {2019},
	booktitle = {arXiv},
	title = {{From self-tuning regulators to reinforcement learning and back again}},
	author = {Nikolai Matni and Alexandre Proutiere and Anders Rantzer and Stephen Tu}
}

