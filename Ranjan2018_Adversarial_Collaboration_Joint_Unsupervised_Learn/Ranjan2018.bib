@article { Ranjan2018,
	abstract = {We address the unsupervised learning of several interconnected problems in
low-level vision: single view depth prediction, camera motion estimation,
optical flow and segmentation of a video into the static scene and moving
regions. Our key insight is that these four fundamental vision problems are
coupled and, consequently, learning to solve them together simplifies the
problem because the solutions can reinforce each other by exploiting known
geometric constraints. In order to model geometric constraints, we introduce
Adversarial Collaboration, a framework that facilitates competition and
collaboration between neural networks. We go beyond previous work by exploiting
geometry more explicitly and segmenting the scene into static and moving
regions. Adversarial Collaboration works much like expectation-maximization but
with neural networks that act as adversaries, competing to explain pixels that
correspond to static or moving regions, and as collaborators through a
moderator that assigns pixels to be either static or independently moving. Our
novel method integrates all these problems in a common framework and
simultaneously reasons about the segmentation of the scene into moving objects
and the static background, the camera motion, depth of the static scene
structure, and the optical flow of moving objects. Our model is trained without
any supervision and achieves state of the art results amongst unsupervised
methods.},
	url = {http://arxiv.org/pdf/1805.09806v1},
	eprint = {1805.09806},
	arxivid = {1805.09806},
	archiveprefix = {arXiv},
	month = {May},
	year = {2018},
	booktitle = {arXiv},
	title = {{Adversarial Collaboration: Joint Unsupervised Learning of Depth, Camera
  Motion, Optical Flow and Motion Segmentation}},
	author = {Anurag Ranjan and Varun Jampani and Kihwan Kim and Deqing Sun and Jonas Wulff and Michael J. Black}
}

